{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec43873-c6ac-4eb4-a62e-d0b807430ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588cef65-c229-434f-bfb9-4d06f43dda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder.appName(\"RealEstateAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb147ae-9145-444c-b158-55c0f4c68e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "csv_file_path = '/sparkbook/project1/realtor-data.csv'\n",
    "\n",
    "homesales_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13bdaaa8-1b2b-4d1a-9815-38f1d7446cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1401066"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display total number of records in dataframe\n",
    "homesales_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d83a922-7604-4fab-816b-a7fdd9126a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+--------+-------------+-----------+--------+----------+--------------+--------+\n",
      "|  status|bed|bath|acre_lot|         city|      state|zip_code|house_size|prev_sold_date|   price|\n",
      "+--------+---+----+--------+-------------+-----------+--------+----------+--------------+--------+\n",
      "|for_sale|3.0| 2.0|    0.12|     Adjuntas|Puerto Rico|   601.0|     920.0|          NULL|105000.0|\n",
      "|for_sale|4.0| 2.0|    0.08|     Adjuntas|Puerto Rico|   601.0|    1527.0|          NULL| 80000.0|\n",
      "|for_sale|2.0| 1.0|    0.15|   Juana Diaz|Puerto Rico|   795.0|     748.0|          NULL| 67000.0|\n",
      "|for_sale|4.0| 2.0|     0.1|        Ponce|Puerto Rico|   731.0|    1800.0|          NULL|145000.0|\n",
      "|for_sale|6.0| 2.0|    0.05|     Mayaguez|Puerto Rico|   680.0|      NULL|          NULL| 65000.0|\n",
      "|for_sale|4.0| 3.0|    0.46|San Sebastian|Puerto Rico|   612.0|    2520.0|          NULL|179000.0|\n",
      "|for_sale|3.0| 1.0|     0.2|       Ciales|Puerto Rico|   639.0|    2040.0|          NULL| 50000.0|\n",
      "|for_sale|3.0| 2.0|    0.08|        Ponce|Puerto Rico|   731.0|    1050.0|          NULL| 71600.0|\n",
      "|for_sale|2.0| 1.0|    0.09|        Ponce|Puerto Rico|   730.0|    1092.0|          NULL|100000.0|\n",
      "|for_sale|5.0| 3.0|    7.46|   Las Marias|Puerto Rico|   670.0|    5403.0|          NULL|300000.0|\n",
      "|for_sale|3.0| 2.0|   13.39|      Isabela|Puerto Rico|   662.0|    1106.0|          NULL| 89000.0|\n",
      "|for_sale|3.0| 2.0|    0.08|   Juana Diaz|Puerto Rico|   795.0|    1045.0|          NULL|150000.0|\n",
      "|for_sale|3.0| 2.0|     0.1|        Lares|Puerto Rico|   669.0|    4161.0|          NULL|155000.0|\n",
      "|for_sale|5.0| 2.0|    0.12|       Utuado|Puerto Rico|   641.0|    1620.0|          NULL| 79000.0|\n",
      "|for_sale|5.0| 5.0|    0.74|        Ponce|Puerto Rico|   731.0|    2677.0|          NULL|649000.0|\n",
      "|for_sale|3.0| 2.0|    0.08|        Yauco|Puerto Rico|   698.0|    1100.0|          NULL|120000.0|\n",
      "|for_sale|4.0| 4.0|    0.22|     Mayaguez|Puerto Rico|   680.0|    3450.0|          NULL|235000.0|\n",
      "|for_sale|3.0| 2.0|    0.08|        Ponce|Puerto Rico|   728.0|    1500.0|          NULL|105000.0|\n",
      "|for_sale|3.0| 2.0|    3.88|San Sebastian|Puerto Rico|   685.0|    4000.0|          NULL|575000.0|\n",
      "|for_sale|6.0| 3.0|    0.25|       Anasco|Puerto Rico|   610.0|    1230.0|          NULL|140000.0|\n",
      "+--------+---+----+--------+-------------+-----------+--------+----------+--------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "homesales_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a96e8b67-7b31-4a8e-b5f2-2e0d2e6a6ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a temporary view of the DataFrame\n",
    "\n",
    "homesales_df.createOrReplaceTempView('property_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "874004b3-5e4e-4dcf-bb3e-add7441665e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+---------+----------+--------------+\n",
      "|  status| bed|avg_price| min_price|     max_price|\n",
      "+--------+----+---------+----------+--------------+\n",
      "|for_sale|NULL|  396,401|      0.00| 75,000,000.00|\n",
      "|for_sale| 1.0|  541,886|      1.00| 79,000,000.00|\n",
      "|for_sale| 2.0|  665,548|      1.00| 16,750,000.00|\n",
      "|for_sale| 3.0|  667,687|      1.00| 35,000,000.00|\n",
      "|for_sale| 4.0|  911,782|      0.00| 66,000,000.00|\n",
      "|for_sale| 5.0|1,519,866|    500.00|135,000,000.00|\n",
      "|for_sale| 6.0|1,607,437|    900.00|169,000,000.00|\n",
      "|for_sale| 7.0|2,185,907|  1,000.00| 59,995,000.00|\n",
      "|for_sale| 8.0|1,864,235| 19,900.00| 69,000,000.00|\n",
      "|for_sale| 9.0|2,647,265| 44,900.00|875,000,000.00|\n",
      "|for_sale|10.0|2,400,350| 75,000.00|100,000,000.00|\n",
      "|for_sale|11.0|2,284,349| 65,000.00| 44,950,000.00|\n",
      "|for_sale|12.0|2,445,001| 49,900.00| 69,950,000.00|\n",
      "|for_sale|13.0|2,856,889| 75,900.00| 40,000,000.00|\n",
      "|for_sale|14.0|4,321,260|195,000.00| 78,000,000.00|\n",
      "|for_sale|15.0|2,614,437|299,000.00| 15,500,000.00|\n",
      "|for_sale|16.0|2,184,158|250,000.00| 45,000,000.00|\n",
      "|for_sale|17.0|2,841,924|280,000.00| 18,000,000.00|\n",
      "|for_sale|18.0|2,038,542|179,900.00| 21,500,000.00|\n",
      "|for_sale|19.0|3,532,226|198,500.00|  9,385,000.00|\n",
      "+--------+----+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# INSIGHT ANALYSIS\n",
    "\n",
    "# 1. Price Distribution by Property Status and Bedroom Count:\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT status, bed, format_number(AVG(price), 0) AS avg_price, format_number(MIN(price), 2) AS min_price, format_number(MAX(price), 2) AS max_price\n",
    "FROM property_sales\n",
    "GROUP BY status, bed\n",
    "ORDER BY status, bed;\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11ebe897-ceff-425d-b875-0a1e474f983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 76:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+--------------+\n",
      "|         city|      state|avg_acre_lot|avg_house_size|\n",
      "+-------------+-----------+------------+--------------+\n",
      "|  Fultonville|   New York|     5446.15|       1948.36|\n",
      "|      Crystal|      Maine|      3900.0|          NULL|\n",
      "|  T13 R8 Wels|      Maine|      3669.0|          NULL|\n",
      "|    Whitehall|   New York|     2989.45|       1647.09|\n",
      "|    Kingsbury|   New York|     2847.45|       1924.84|\n",
      "|      Whiting| New Jersey|     2411.32|        1328.2|\n",
      "|     Simsbury|Connecticut|      2179.8|       2215.14|\n",
      "|     Hato Rey|Puerto Rico|      1700.0|        1700.0|\n",
      "|Scotch Plains| New Jersey|     1619.94|       3523.22|\n",
      "|   T3 R1 Nbpp|      Maine|      1503.0|          NULL|\n",
      "+-------------+-----------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 2. Average Lot Size and House Size by City and State:\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT city, state, ROUND(AVG(acre_lot), 2) AS avg_acre_lot, ROUND(AVG(house_size), 2) AS avg_house_size\n",
    "FROM property_sales\n",
    "GROUP BY city, state\n",
    "ORDER BY avg_acre_lot DESC, avg_house_size DESC;\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21c9418f-3c63-4eb0-9f16-861ddaad5b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|zip_code|avg_price_per_sqft|\n",
      "+--------+------------------+\n",
      "|    2215|            997.29|\n",
      "|   10027|            995.18|\n",
      "|    5842|             99.98|\n",
      "|   13440|             99.66|\n",
      "|     795|             99.57|\n",
      "|   13144|             99.49|\n",
      "|   13114|             99.45|\n",
      "|    4357|             99.39|\n",
      "|    8609|             99.26|\n",
      "|   14218|             99.26|\n",
      "+--------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 3. Price Per Square Foot Analysis by Zip Code:\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT int(zip_code), format_number(AVG(price/house_size), 2) AS avg_price_per_sqft\n",
    "FROM property_sales\n",
    "WHERE house_size > 0\n",
    "GROUP BY zip_code\n",
    "ORDER BY avg_price_per_sqft DESC;\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6f23490b-9c5f-4cef-9676-75d978dedd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 112:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+------------+\n",
      "|      state|year|   avg_price|\n",
      "+-----------+----+------------+\n",
      "|Connecticut|1961|2,100,000.00|\n",
      "|Connecticut|1963|  339,000.00|\n",
      "|Connecticut|1965|  313,083.33|\n",
      "|Connecticut|1966|  328,185.71|\n",
      "|Connecticut|1967|  544,366.67|\n",
      "|Connecticut|1968|  184,900.00|\n",
      "|Connecticut|1970|2,850,000.00|\n",
      "|Connecticut|1971|  303,999.40|\n",
      "|Connecticut|1972|  379,000.00|\n",
      "|Connecticut|1973|  534,764.00|\n",
      "+-----------+----+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 4. Year-over-Year Price Growth by State:\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT state, YEAR(prev_sold_date) AS year, format_number(AVG(price), 2) AS avg_price\n",
    "FROM property_sales\n",
    "where YEAR(prev_sold_date) is not null\n",
    "GROUP BY state, year\n",
    "ORDER BY state, year;\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f414a536-8fc7-48d3-8733-cf60639feb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg_days_on_market|\n",
      "+------------------+\n",
      "| 5338.398466366245|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Market Velocity: Time Between Listings and Previous Sale:\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT AVG(DATEDIFF(current_date, prev_sold_date)) AS avg_days_on_market\n",
    "FROM property_sales\n",
    "WHERE prev_sold_date IS NOT NULL;\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1adbd357-88e3-4f16-936c-36971cbfcef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|bath_bed_ratio|   avg_price|\n",
      "+--------------+------------+\n",
      "|          0.26|  985,000.00|\n",
      "|          0.42|  981,799.99|\n",
      "|          0.64|  975,482.14|\n",
      "|          3.33|   95,000.00|\n",
      "|          0.68|9,950,000.00|\n",
      "|          1.89|9,875,000.00|\n",
      "|          1.29|9,569,547.88|\n",
      "|          1.88|9,500,000.00|\n",
      "|          1.26|9,385,000.00|\n",
      "|          0.65|9,162,166.67|\n",
      "+--------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 6. Impact of Bathrooms to Bedrooms Ratio on Price:\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT ROUND(bath/bed, 2) AS bath_bed_ratio, format_number(AVG(price), 2) AS avg_price\n",
    "FROM property_sales\n",
    "WHERE bed > 0 AND bath > 0\n",
    "GROUP BY bath_bed_ratio\n",
    "ORDER BY avg_price DESC;\n",
    "\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8f0e56e-1c35-42f0-8983-ae3f7c8a97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 148:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+--------+-----+\n",
      "|              city|        state|  status|count|\n",
      "+------------------+-------------+--------+-----+\n",
      "|             Abbot|        Maine|for_sale|   15|\n",
      "|          Aberdeen|   New Jersey|for_sale|  210|\n",
      "|          Abington|Massachusetts|for_sale|  166|\n",
      "|          Abington| Pennsylvania|for_sale|   13|\n",
      "|           Absecon|   New Jersey|for_sale|  353|\n",
      "| Absecon Highlands|   New Jersey|for_sale|    4|\n",
      "|            Accord|     New York|for_sale|  362|\n",
      "|              Acra|     New York|for_sale|   50|\n",
      "|             Acton|        Maine|for_sale|   53|\n",
      "|             Acton|Massachusetts|for_sale|  798|\n",
      "|          Acushnet|Massachusetts|for_sale|   97|\n",
      "|           Acworth|New Hampshire|for_sale|  131|\n",
      "|             Adams|Massachusetts|for_sale|  935|\n",
      "|             Adams|     New York|for_sale|  124|\n",
      "|      Adams Center|     New York|for_sale|   42|\n",
      "|Adamstown Township|        Maine|for_sale|    7|\n",
      "|   Addisleigh Park|     New York|for_sale|   53|\n",
      "|           Addison|        Maine|for_sale|   93|\n",
      "|           Addison|      Vermont|for_sale|   54|\n",
      "|          Adelphia|   New Jersey|for_sale|    3|\n",
      "+------------------+-------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time taken is: 0.9592514038085938 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 7. Frequency of Properties for Sale vs. Ready to Build by Location\n",
    "# and  determinining the run time for this query:\n",
    "start_time = time.time()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT city, state, status, COUNT(*) AS count\n",
    "FROM property_sales\n",
    "where city is not NULL and status is not NULL\n",
    "GROUP BY city, state, status\n",
    "ORDER BY city, state, status;\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"Time taken is: %s seconds\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fafeb261-6609-4177-8671-6798210b98bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Cache the the temporary table property_sales.\n",
    "\n",
    "spark.sql('CACHE TABLE property_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02da4f47-732c-4c25-b64b-ee3040c93ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+--------+-----+\n",
      "|             city|        state|  status|count|\n",
      "+-----------------+-------------+--------+-----+\n",
      "|            Abbot|        Maine|for_sale|   15|\n",
      "|         Aberdeen|   New Jersey|for_sale|  210|\n",
      "|         Abington|Massachusetts|for_sale|  166|\n",
      "|         Abington| Pennsylvania|for_sale|   13|\n",
      "|          Absecon|   New Jersey|for_sale|  353|\n",
      "|Absecon Highlands|   New Jersey|for_sale|    4|\n",
      "|           Accord|     New York|for_sale|  362|\n",
      "|             Acra|     New York|for_sale|   50|\n",
      "|            Acton|        Maine|for_sale|   53|\n",
      "|            Acton|Massachusetts|for_sale|  798|\n",
      "+-----------------+-------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time taken with data cached is: 0.3111600875854492 seconds\n"
     ]
    }
   ],
   "source": [
    "# 9. Running the query 7 using the cached data, calculate runtime and compare it to uncached runtime.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT city, state, status, COUNT(*) AS count\n",
    "FROM property_sales\n",
    "where city is not NULL and status is not NULL\n",
    "GROUP BY city, state, status\n",
    "ORDER BY city, state, status;\n",
    "\"\"\").show(10)\n",
    "\n",
    "print(\"Time taken with data cached is: %s seconds\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4f0badea-2e30-4411-8e54-1538d2311a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 10. Partitioning by the \"state\" field on the formatted parquet home sales data\n",
    "\n",
    "homesales_df.write.partitionBy('state').parquet('parquet_property_sales', mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c35fa108-4ad1-44eb-9197-21fea5b8dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Reading the formatted parquet data\n",
    "\n",
    "parquet_df = spark.read.parquet('parquet_property_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9c69e106-7943-4cee-a089-50a21aba4a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----+--------+----------+--------+----------+--------------+--------+--------+\n",
      "|  status|bed|bath|acre_lot|      city|zip_code|house_size|prev_sold_date|   price|   state|\n",
      "+--------+---+----+--------+----------+--------+----------+--------------+--------+--------+\n",
      "|for_sale|5.0| 3.0|    0.14|   Merrick| 11566.0|      NULL|    1993-02-22|894990.0|New York|\n",
      "|for_sale|4.0| 3.0|    0.15|Hicksville| 11801.0|      NULL|          NULL|799999.0|New York|\n",
      "|for_sale|5.0| 4.0|    0.18| Plainview| 11803.0|    2807.0|    1986-01-31|998000.0|New York|\n",
      "|for_sale|4.0| 3.0|    0.18| Plainview| 11803.0|      NULL|    1986-04-04|925000.0|New York|\n",
      "|for_sale|4.0| 4.0|    0.14|   Merrick| 11566.0|      NULL|          NULL|875000.0|New York|\n",
      "+--------+---+----+--------+----------+--------+----------+--------------+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquet_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "15ea668d-3e15-4059-8e4e-d1da81275e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken with parquet data is: 4.172325134277344e-05 seconds\n"
     ]
    }
   ],
   "source": [
    "# 12. Runing the query 7 with the parquet DataFrame\n",
    "# Determining the runtime and comparing it to the cached version.\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\"\"\"\n",
    "SELECT city, state, status, COUNT(*) AS count\n",
    "FROM parquet_df\n",
    "where city is not NULL and status is not NULL\n",
    "GROUP BY city, state, status\n",
    "ORDER BY city, state, status;\n",
    "\"\"\"\n",
    "\n",
    "print(\"Time taken with parquet data is: %s seconds\" %(time.time() - start_time))\n",
    "\n",
    "# 0.00004172325 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40e0cb1b-f095-4a01-b3b8-88665ece9cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('UNCACHE TABLE property_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13dc7f1e-d4e6-4ac8-a8d7-f9299b927be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home_sales is not cached\n"
     ]
    }
   ],
   "source": [
    "# 13. Checking if the property_sales is no longer cached\n",
    "if spark.catalog.isCached('property_sales'):\n",
    "  print('home_sales is cached')\n",
    "else:\n",
    "  print('home_sales is not cached')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9708f2a8-3656-4329-ba23-dcce38fe3927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"id\": \"driver\",\n",
      "        \"hostPort\": \"172.25.195.172:38923\",\n",
      "        \"isActive\": true,\n",
      "        \"rddBlocks\": 0,\n",
      "        \"memoryUsed\": 35109,\n",
      "        \"diskUsed\": 0,\n",
      "        \"totalCores\": 8,\n",
      "        \"maxTasks\": 8,\n",
      "        \"activeTasks\": 0,\n",
      "        \"failedTasks\": 0,\n",
      "        \"completedTasks\": 514,\n",
      "        \"totalTasks\": 514,\n",
      "        \"totalDuration\": 8981395,\n",
      "        \"totalGCTime\": 2699,\n",
      "        \"totalInputBytes\": 5298459785,\n",
      "        \"totalShuffleRead\": 7474579,\n",
      "        \"totalShuffleWrite\": 7474579,\n",
      "        \"isBlacklisted\": false,\n",
      "        \"maxMemory\": 455501414,\n",
      "        \"addTime\": \"2024-02-27T06:05:53.529GMT\",\n",
      "        \"executorLogs\": {},\n",
      "        \"memoryMetrics\": {\n",
      "            \"usedOnHeapStorageMemory\": 35109,\n",
      "            \"usedOffHeapStorageMemory\": 0,\n",
      "            \"totalOnHeapStorageMemory\": 455501414,\n",
      "            \"totalOffHeapStorageMemory\": 0\n",
      "        },\n",
      "        \"blacklistedInStages\": [],\n",
      "        \"peakMemoryMetrics\": {\n",
      "            \"JVMHeapMemory\": 435197760,\n",
      "            \"JVMOffHeapMemory\": 268513760,\n",
      "            \"OnHeapExecutionMemory\": 31194912,\n",
      "            \"OffHeapExecutionMemory\": 0,\n",
      "            \"OnHeapStorageMemory\": 74072210,\n",
      "            \"OffHeapStorageMemory\": 0,\n",
      "            \"OnHeapUnifiedMemory\": 74072210,\n",
      "            \"OffHeapUnifiedMemory\": 0,\n",
      "            \"DirectPoolMemory\": 721961,\n",
      "            \"MappedPoolMemory\": 0,\n",
      "            \"ProcessTreeJVMVMemory\": 0,\n",
      "            \"ProcessTreeJVMRSSMemory\": 0,\n",
      "            \"ProcessTreePythonVMemory\": 0,\n",
      "            \"ProcessTreePythonRSSMemory\": 0,\n",
      "            \"ProcessTreeOtherVMemory\": 0,\n",
      "            \"ProcessTreeOtherRSSMemory\": 0,\n",
      "            \"MinorGCCount\": 607,\n",
      "            \"MinorGCTime\": 2356,\n",
      "            \"MajorGCCount\": 4,\n",
      "            \"MajorGCTime\": 343,\n",
      "            \"TotalGCTime\": 2699\n",
      "        },\n",
      "        \"attributes\": {},\n",
      "        \"resources\": {},\n",
      "        \"resourceProfileId\": 0,\n",
      "        \"isExcluded\": false,\n",
      "        \"excludedInStages\": []\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# 14. #code snippet that demonstrates how to fetch executor information from the Spark REST API.\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def fetch_executor_details():\n",
    "    # URL for the Spark REST API endpoint for executors\n",
    "    spark_rest_api_url = 'http://localhost:4040/api/v1/applications'\n",
    "    \n",
    "    # Fetch list of applications\n",
    "    apps_response = requests.get(spark_rest_api_url)\n",
    "    apps = apps_response.json()\n",
    "    \n",
    "    if not apps:\n",
    "        print(\"No applications found.\")\n",
    "        return\n",
    "    \n",
    "    # details from the first application\n",
    "    app_id = apps[0]['id']\n",
    "    \n",
    "    # Construct URL to fetch executor details for the application\n",
    "    executors_url = f'{spark_rest_api_url}/{app_id}/executors'\n",
    "    \n",
    "    # Fetch executor details\n",
    "    executors_response = requests.get(executors_url)\n",
    "    executors = executors_response.json()\n",
    "    \n",
    "    # Pretty print the executor details\n",
    "    print(json.dumps(executors, indent=4))\n",
    "\n",
    "# Call the function to fetch and print executor details\n",
    "fetch_executor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3434208d-648d-410b-89e3-bbf199e03923",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
